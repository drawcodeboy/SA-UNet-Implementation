{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9e7e17-e96c-4c88-b27d-eb425fa4717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import threshold\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from copy import copy, deepcopy\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.ops import drop_block2d\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a465218-6bfe-41f8-ba96-17e03f06d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropBlock(nn.Module):\n",
    "    def __init__(self, block_size, keep_prob=0.9, sync_channel=False):\n",
    "        super(DropBlock, self).__init__()\n",
    "        '''\n",
    "        block_size : feature에서 drop 시킬 block의 크기, 반드시 홀수여야 함.\n",
    "        keep_prob : 계속 activation 시킬 Probability\n",
    "        논문에서는 Keep Probability에 대해 학습을 하면서 1부터 알맞는 값까지\n",
    "        선형적으로 학습하여 적합한 p값을 찾아야 한다 하지만, 그 부분은 구현이 꽤\n",
    "        어려워서 0.9를 default로 모델링을 한다.\n",
    "        '''\n",
    "        self.block_size = block_size\n",
    "        self.keep_prob = keep_prob\n",
    "        self.sync_channel = sync_channel\n",
    "        self.padding_size = (self.block_size-1)//2\n",
    "\n",
    "    def getGamma(self, feat_size):\n",
    "        '''\n",
    "        Gamma의 역할\n",
    "        Traditional한 Dropout에서 1-keep_prob을 통해 베르누이 분포를 계산하여\n",
    "        Dropout을 진행하는데 이 부분이 DropBlock에서는 영역적으로\n",
    "        block_size에 따라 Drop하기 때문에 이 부분을 고려하여 아래와 같이\n",
    "        Gamma를 계산하여 베르누이 분포의 Drop 시킬 확률 값으로 넘기도록 한다.\n",
    "        '''\n",
    "        return (1.0-self.keep_prob)/(self.block_size**2)*(feat_size**2)/((feat_size-self.block_size+1)**2)\n",
    "\n",
    "    def dropMask(self, feat_size):\n",
    "        '''\n",
    "        여기서 (1-keep_prob)기반 Gamma를 토대로 Bernoulli를 쓰는 것이기 때문에\n",
    "        1이 Drop할 Center Pixel이다.\n",
    "        '''\n",
    "        mask = torch.distributions.Bernoulli(probs=self.getGamma(feat_size)).sample((feat_size, feat_size))\n",
    "        return mask\n",
    "\n",
    "    def outOfRegion(self, mask_pixel):\n",
    "        '''\n",
    "        Mask할 Region들이 Block Size로 인해 feature map을 넘어가지 않도록\n",
    "        feature map 내에서 fully하게 Drop할 수 있도록 테두리 부분에\n",
    "        Mask 픽셀이 있는 경우 이를 제거 한다.\n",
    "        '''\n",
    "        mask_pixel[0:self.padding_size, :] = 0.\n",
    "        mask_pixel[-self.padding_size:, :] = 0.\n",
    "        mask_pixel[:, 0:self.padding_size] = 0.\n",
    "        mask_pixel[:, -self.padding_size:] = 0.\n",
    "        return mask_pixel\n",
    "\n",
    "    def getRegion(self, mask_region):\n",
    "        masking_li = []\n",
    "        for i in range(0, mask_region.shape[0]):\n",
    "            for j in range(0, mask_region.shape[1]):\n",
    "                if mask_region[i][j] == 1.0:\n",
    "                    masking_li.append((i, j))\n",
    "\n",
    "        for (i, j) in masking_li:\n",
    "            mask_region[i-self.padding_size:i+self.padding_size+1,j-self.padding_size:j+self.padding_size+1]=1.0\n",
    "        return mask_region\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat_size = x.shape[-1]\n",
    "        n_channels = x.shape[-3]\n",
    "        \n",
    "        if self.sync_channel:\n",
    "            '''\n",
    "            논문 실험에서는 channel 다 통합한 같은 Masking보다\n",
    "            독립적으로 하는 게 더 성능이 좋다해서 이 부분은 사용 안 할 듯\n",
    "            '''\n",
    "            mask = torch.where(\\\n",
    "                    self.getRegion(\\\n",
    "                        self.outOfRegion(\\\n",
    "                            self.dropMask(feat_size))) == 1, 0, 1).float()\n",
    "            x = x * mask\n",
    "            return x\n",
    "        else:\n",
    "            # Channel에 따라 독립적으로 Dropout\n",
    "            mask = torch.stack(\n",
    "                [torch.where(\\\n",
    "                    self.getRegion(\\\n",
    "                        self.outOfRegion(\\\n",
    "                            self.dropMask(feat_size))) == 1, 0, 1).float()\\\n",
    "                                 for _ in range(n_channels)], dim=0)\n",
    "            x = x * mask\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0d2ffd-ed7a-4b3c-b730-4709d3a178be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropBlock(input, block_size, keep_prob=0.9):\n",
    "    N, C, H, W = input.size()\n",
    "    block_size = min(block_size, W, H)\n",
    "    gamma = (1.0-keep_prob)*H*W / ((block_size**2) * ((H - block_size + 1) * (W - block_size + 1)))\n",
    "    noise = torch.empty((N, C, H - block_size + 1, W - block_size + 1), dtype=input.dtype, device=input.device)\n",
    "    noise.bernoulli_(gamma)\n",
    "\n",
    "    noise = F.pad(noise, [block_size // 2] * 4, value=0)\n",
    "    noise = F.max_pool2d(noise, stride=(1, 1), kernel_size=(block_size, block_size), padding=block_size // 2)\n",
    "    noise = 1 - noise\n",
    "    return input * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac2aac-36ff-4846-ac08-e84550d4f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=3\n",
    "sample = torch.rand((3, channels, 224, 224))\n",
    "sample_db = dropBlock(sample, block_size=51, keep_prob=0.9)\n",
    "\n",
    "ch_cnt = 1\n",
    "for i in range(1, channels+1):\n",
    "    plt.subplot(channels, 2, i*2-1)\n",
    "    plt.imshow(to_pil_image(sample[0][i-1]))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'ch{ch_cnt} orig')\n",
    "\n",
    "    plt.subplot(channels, 2, i*2)\n",
    "    plt.imshow(to_pil_image(sample_db[0][i-1]))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'ch{ch_cnt} DropBlock')\n",
    "    ch_cnt += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a21e6-cd08-497c-9927-887eadd6481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttentionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttentionModule, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=7, stride=1, padding=3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        maxPool = torch.max(x, dim=-3)[0].unsqueeze(dim=-3)\n",
    "        avgPool = torch.mean(x, dim=-3).unsqueeze(dim=-3)\n",
    "        print(maxPool.shape, avgPool.shape)\n",
    "        concat = torch.cat([maxPool, avgPool], dim=-3)\n",
    "        print(concat.shape)\n",
    "        SA = self.conv(concat)\n",
    "        print(SA.shape)\n",
    "        x = x * SA\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb03adf-b84c-4894-ac43-22e9e1a94efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((16, 14, 224, 224))\n",
    "\n",
    "SAM = SpatialAttentionModule()\n",
    "b = SAM(a)\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f967e3-21ae-4e6d-a32e-8851caa2e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, block_size, keep_prob):\n",
    "        super().__init__()\n",
    "\n",
    "        # Block Size는 이미지 사이즈의 10%인 22로 설정\n",
    "        self.conv1 = nn.Conv2d(in_filters, out_filters, kernel_size=3, padding=1)\n",
    "        #self.drop1 = DropBlock(block_size=block_size, keep_prob=keep_prob)\n",
    "        self.bn1 = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_filters, out_filters, kernel_size=3, padding=1)\n",
    "        #self.drop2 = DropBlock(block_size=block_size, keep_prob=keep_prob)\n",
    "        self.bn2 = nn.BatchNorm2d(out_filters)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.training == True:\n",
    "            x = dropBlock(x, \n",
    "                          block_size=(x.shape[-1]//5 if x.shape[-1]//5%2==1 else x.shape[-1]//5+1), \n",
    "                          keep_prob=0.9)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        if self.training == True:\n",
    "            x = dropBlock(x, \n",
    "                          block_size=(x.shape[-1]//5 if x.shape[-1]//5%2==1 else x.shape[-1]//5+1), \n",
    "                          keep_prob=0.9)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b6c4d-7157-4329-9f72-e3067e31b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, block_size, keep_prob):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.convBlk = ConvBlock(in_filters, out_filters, block_size=block_size, keep_prob=keep_prob)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convBlk(x)\n",
    "        p = self.pool(x)\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286324f-27eb-4d2d-b16d-1240b62a24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, block_size, keep_prob):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.transposeConv = nn.ConvTranspose2d(in_filters, out_filters, kernel_size=2, stride=2)\n",
    "        self.convBlk = ConvBlock(in_filters, out_filters, block_size=block_size, keep_prob=keep_prob)\n",
    "        \n",
    "    def forward(self, x, skip):\n",
    "        x = self.transposeConv(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convBlk(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f1abb-ac6e-4f19-bb92-e3bc02e4d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SA_UNet(nn.Module):\n",
    "    def __init__(self, channel, block_size, keep_prob=0.9):\n",
    "        super(SA_UNet, self).__init__()\n",
    "\n",
    "        # Constracting Path block_size = block_size, keep_prob = keep_prob\n",
    "        self.e1 = EncoderBlock(channel, 16, block_size=block_size, keep_prob=keep_prob)\n",
    "        self.e2 = EncoderBlock(16, 32, block_size=block_size, keep_prob=keep_prob)\n",
    "        self.e3 = EncoderBlock(32, 64, block_size=block_size, keep_prob=keep_prob)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        #self.drop1 = DropBlock(block_size=block_size, keep_prob=keep_prob)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Bridge\n",
    "        self.sam = SpatialAttentionModule()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        #self.drop2 = DropBlock(block_size=block_size, keep_prob=keep_prob)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Expanding Path\n",
    "        self.d1 = DecoderBlock(128, 64, block_size=block_size, keep_prob=keep_prob)\n",
    "        self.d2 = DecoderBlock(64, 32, block_size=block_size, keep_prob=keep_prob)\n",
    "        self.d3 = DecoderBlock(32, 16, block_size=block_size, keep_prob=keep_prob)\n",
    "\n",
    "        self.convOut = nn.Conv2d(16, 1, kernel_size=1, stride=1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1, p1 = self.e1(x)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, b = self.e3(p2)\n",
    "\n",
    "        b = self.conv1(b)\n",
    "        if self.training == True:\n",
    "            b = dropBlock(b, \n",
    "                          block_size=(b.shape[-1]//5 if b.shape[-1]//5%2==1 else b.shape[-1]//5+1), \n",
    "                          keep_prob=0.9)\n",
    "        b = self.bn1(b)\n",
    "        b = self.relu(b)\n",
    "\n",
    "        b = self.sam(b)\n",
    "\n",
    "        b = self.conv2(b)\n",
    "        if self.training == True:\n",
    "            b = dropBlock(b, \n",
    "                          block_size=(b.shape[-1]//5 if b.shape[-1]//5%2==1 else b.shape[-1]//5+1), \n",
    "                          keep_prob=0.9)\n",
    "        b = self.bn2(b)\n",
    "        b = self.relu(b)\n",
    "\n",
    "        d1 = self.d1(b, s3)\n",
    "        d2 = self.d2(d1, s2)\n",
    "        d3 = self.d3(d2, s1)\n",
    "\n",
    "        output = self.convOut(d3)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3bf48-123b-488b-8b91-71c135f9b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "testNet = SA_UNet(channel=1, block_size=22, keep_prob=0.9).to('cuda')\n",
    "testNet.train()\n",
    "summary(testNet, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13f087a-83bc-4dd5-9a89-51ad6c337b1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m testNet\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      2\u001b[0m summary(testNet, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testNet' is not defined"
     ]
    }
   ],
   "source": [
    "testNet.eval()\n",
    "summary(testNet, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d5a6c3c-c4a9-4a3d-b630-0ef492c50b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T12:44:56.830948Z",
     "iopub.status.busy": "2024-01-22T12:44:56.829954Z",
     "iopub.status.idle": "2024-01-22T12:44:56.839924Z",
     "shell.execute_reply": "2024-01-22T12:44:56.838927Z",
     "shell.execute_reply.started": "2024-01-22T12:44:56.830948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA_UNet(\n",
      "  (e1): EncoderBlock(\n",
      "    (convBlk): ConvBlock(\n",
      "      (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop1): DropBlock()\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop2): DropBlock()\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e2): EncoderBlock(\n",
      "    (convBlk): ConvBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop1): DropBlock()\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop2): DropBlock()\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e3): EncoderBlock(\n",
      "    (convBlk): ConvBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop1): DropBlock()\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop2): DropBlock()\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (drop1): DropBlock()\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (sam): SpatialAttentionModule(\n",
      "    (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (drop2): DropBlock()\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d1): DecoderBlock(\n",
      "    (transposeConv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (convBlk): ConvBlock(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop1): DropBlock()\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop2): DropBlock()\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (d2): DecoderBlock(\n",
      "    (transposeConv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (convBlk): ConvBlock(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop1): DropBlock()\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop2): DropBlock()\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (d3): DecoderBlock(\n",
      "    (transposeConv): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (convBlk): ConvBlock(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop1): DropBlock()\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop2): DropBlock()\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (convOut): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (sigmoid): Sigmoid()\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(testNet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
